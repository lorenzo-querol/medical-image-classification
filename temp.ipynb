{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1176090181.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    import cv2import os\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from utils import prepare_datasets\n",
    "from config import config\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8980 files belonging to 2 classes.\n",
      "Found 1448 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-04 16:13:00.672097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 236 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 255.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, valid_dataset = prepare_datasets(\n",
    "    \"Dataset/extracted/train\", \"Dataset/extracted/val\", config\n",
    ")\n",
    "\n",
    "images, labels = train_dataset.as_numpy_iterator().next()\n",
    "np.min(images), np.max(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_resize(image, target_size=(224, 224), negative_space_color=(0, 0, 0)):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold to get a binary mask of the content\n",
    "    _, thresh = cv2.threshold(\n",
    "        gray, 10, 255, cv2.THRESH_BINARY\n",
    "    )  # Assuming black background\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # If no contours are detected, just return the resized image\n",
    "    if not contours:\n",
    "        return cv2.resize(image, target_size)\n",
    "\n",
    "    # Find the bounding box of the content\n",
    "    x, y, w, h = cv2.boundingRect(contours[0])\n",
    "    for contour in contours:\n",
    "        x_, y_, w_, h_ = cv2.boundingRect(contour)\n",
    "        x = min(x, x_)\n",
    "        y = min(y, y_)\n",
    "        w = max(x + w, x_ + w_) - x\n",
    "        h = max(y + h, y_ + h_) - y\n",
    "\n",
    "    # Crop the image to this bounding box\n",
    "    cropped = image[y : y + h, x : x + w]\n",
    "\n",
    "    # Resize the cropped image to the target size\n",
    "    resized = cv2.resize(cropped, target_size)\n",
    "\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory\n",
    "base_dir = \"Dataset/extracted\"\n",
    "save_base_dir = \"Dataset/cropped\"\n",
    "\n",
    "# Ensure the save directory exists\n",
    "if not os.path.exists(save_base_dir):\n",
    "    os.makedirs(save_base_dir)\n",
    "\n",
    "# Iterate through each sub-directory: train, val, test\n",
    "for subset in [\"train\", \"val\", \"test\"]:\n",
    "    subset_dir = os.path.join(base_dir, subset)\n",
    "    save_subset_dir = os.path.join(save_base_dir, subset)\n",
    "\n",
    "    # Ensure the subset save directory exists\n",
    "    if not os.path.exists(save_subset_dir):\n",
    "        os.makedirs(save_subset_dir)\n",
    "\n",
    "    # Iterate through class folders: 0 and 1\n",
    "    for class_label in [\"0\", \"1\"]:\n",
    "        class_dir = os.path.join(subset_dir, class_label)\n",
    "        save_class_dir = os.path.join(save_subset_dir, class_label)\n",
    "\n",
    "        # Ensure the class save directory exists\n",
    "        if not os.path.exists(save_class_dir):\n",
    "            os.makedirs(save_class_dir)\n",
    "\n",
    "        # List all image files in the directory\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            save_img_path = os.path.join(save_class_dir, img_name)\n",
    "\n",
    "            # Load the image\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            # Process the image\n",
    "            processed_img = crop_and_resize(img)\n",
    "\n",
    "            # Save the processed image\n",
    "            cv2.imwrite(save_img_path, processed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m images, labels \u001b[39m=\u001b[39m train_dataset\u001b[39m.\u001b[39mas_numpy_iterator()\u001b[39m.\u001b[39mnext()\n\u001b[1;32m      4\u001b[0m img_array \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m      6\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m, \u001b[39m12\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images, labels = train_dataset.as_numpy_iterator().next()\n",
    "img_array = images.copy()\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(32):\n",
    "    plt.subplot(6, 6, (i + 1))\n",
    "    plt.imshow(img_array[i] / 255)\n",
    "    plt.title(labels[i])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.legend\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MedicalImageClassification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
